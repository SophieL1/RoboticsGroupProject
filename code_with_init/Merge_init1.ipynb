{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8979e539-0a60-4175-8abd-5713634b96ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "from cv2 import aruco\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "\n",
    "#fonction Sophie\n",
    "from findPath import findPath\n",
    "\n",
    "#fonction Liandro\n",
    "from camera import read_camera_image\n",
    "#from get_corner import get_corner\n",
    "#from get_obstacles_coordinates import get_obstacles_coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8145849-fbdf-4752-947f-3d3f3fe3c833",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_corner(gray):\n",
    "    \"\"\"\n",
    "    Get the coordinates of the corners on the real camera image\n",
    "    \"\"\"\n",
    "    height, width = gray.shape\n",
    "    \n",
    "    # Initialization of the ArUco dictionary\n",
    "    aruco_dict = aruco.getPredefinedDictionary(cv2.aruco.DICT_4X4_50)\n",
    "    parameters = aruco.DetectorParameters()\n",
    "    \n",
    "    keypoints_coordinates = []\n",
    "    \n",
    "    # Detection of ArUco markers\n",
    "    corners, ids, rejectedImgPoints = aruco.detectMarkers(gray, aruco_dict, parameters=parameters)\n",
    "\n",
    "    # If markers are detected\n",
    "    if ids is not None:\n",
    "        for i, marker_id in enumerate(ids):\n",
    "            if marker_id < 4:  # get only the code 0-1-2-3 which are the corners\n",
    "                keypoints_coordinates.append(corners[i][0][0])  # Append the corners of the marker\n",
    "        keypoints_coordinates = [keypoint.astype(int).tolist() for keypoint in keypoints_coordinates]\n",
    "\n",
    "        # Verify if there are 4 coordinates\n",
    "        if len(keypoints_coordinates) == 4:\n",
    "            # reference point for the calculation of the distance\n",
    "            reference_points = np.array([[0, 0], [width-1, 0], [width-1, height-1], [0, height-1]], dtype=np.float32)\n",
    "            \n",
    "            def distance(point1, point2):\n",
    "                return np.sqrt((point1[0] - point2[0])**2 + (point1[1] - point2[1])**2)\n",
    "\n",
    "            # Distance between points and corners\n",
    "            distances = np.array([[distance(point, ref) for ref in reference_points] for point in keypoints_coordinates])\n",
    "\n",
    "            # Find corner with min distance for each corner\n",
    "            closest_references = np.argmin(distances, axis=1)\n",
    "\n",
    "            # Re-organisation of the points and keep the closest one\n",
    "            corner_coordinates = [keypoints_coordinates[i] for i in np.argsort(closest_references)]\n",
    "        else:\n",
    "            corner_coordinates = None\n",
    "    else :\n",
    "        corner_coordinates = None\n",
    "    return corner_coordinates;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10aaf605-be3e-4afe-9c0a-1c3e3efb0185",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def crop_image(img, coordinates):\n",
    "    \"\"\"\n",
    "    Crop the image between the 4 patterns in the corners\n",
    "    \"\"\"\n",
    "    new_width = 605\n",
    "    new_height = 570\n",
    "    \n",
    "    # Use the coordinates to obtain the transformation matrix\n",
    "    original_points = np.array(coordinates, dtype=np.float32)\n",
    "    destination_points = np.array([[0, 0], [new_width-1, 0], [new_width-1, new_height-1], [0, new_height-1]], dtype=np.float32)\n",
    "\n",
    "    matrix = cv2.getPerspectiveTransform(original_points, destination_points)\n",
    "\n",
    "    # Apply the perspective transformation to the original image\n",
    "    img_crop = cv2.warpPerspective(img, matrix, (new_width, new_height))\n",
    "    return img_crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02e02021-a67a-4981-b1ac-1f3f49f888fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def visionning(img,gray,img_crop,img_obstacles):\n",
    "    \"\"\"\n",
    "    This function can combine 4 images in one for visualisation on live\n",
    "    \"\"\"\n",
    "    img1 = img\n",
    "    img2 = cv2.cvtColor(gray, cv2.COLOR_GRAY2BGR)\n",
    "    img3 = cv2.cvtColor(cv2.resize(img_crop, (gray.shape[1], gray.shape[0])), cv2.COLOR_GRAY2BGR)\n",
    "    img4 = cv2.cvtColor(cv2.resize(img_obstacles, (gray.shape[1], gray.shape[0])), cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    combined_image1 = np.hstack((img1, img2))\n",
    "    combined_image2 = np.hstack((img3, img4))\n",
    "    combined_image = np.vstack((combined_image1, combined_image2))\n",
    "    return combined_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16ef3c74-1436-47e4-b6b5-94dfc4be2391",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_position_orientation_thymio(img):\n",
    "    \"\"\"\n",
    "    Get the position and the orientation of the thymio\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialization of the ArUco dictionary\n",
    "    aruco_dict = aruco.getPredefinedDictionary(cv2.aruco.DICT_4X4_50)\n",
    "    parameters = aruco.DetectorParameters()\n",
    "    \n",
    "    keypoints_coordinates = []\n",
    "    \n",
    "    # Detection of ArUco markers\n",
    "    corners, ids, rejectedImgPoints = aruco.detectMarkers(img, aruco_dict, parameters=parameters)\n",
    "\n",
    "    # If markers are detected\n",
    "    if ids is not None:\n",
    "        for i, marker_id in enumerate(ids):\n",
    "            if marker_id == 4:  # get only the 4th which is the thymio\n",
    "                \n",
    "                # Position\n",
    "                position = np.mean(corners[i][0], axis=0)\n",
    "                #print(\"Position - \\n\", position)\n",
    "                \n",
    "                # Orientation of the robot\n",
    "                vector = corners[i][0][0] - corners[i][0][3]\n",
    "                x_axis_vector = np.array([1, 0])  # Vector along the x-axis\n",
    "                angle_radians = np.arctan2(np.linalg.det([vector, x_axis_vector]), np.dot(vector, x_axis_vector))\n",
    "                orientation = -np.degrees(angle_radians)\n",
    "                #print(\"Orientation - \\n\", orientation)\n",
    "                \n",
    "                keypoints_coordinates.append(corners[i][0][0])  # Append the corners of the marker\n",
    "        keypoints_coordinates = [keypoint.astype(int).tolist() for keypoint in keypoints_coordinates]\n",
    "    # Placeholder for position and orientation (modify accordingly)\n",
    "    raw_camera_measurement = [int(position[0]), int(position[1]), round(orientation,2)]\n",
    "\n",
    "    #return position,orientation\n",
    "    return raw_camera_measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b996930-8179-491c-9913-a319f3619312",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_obstacles_coordinates(img,pos_goal):\n",
    "    \"\"\"\n",
    "    Get the corner of the obstacles\n",
    "        - mask the pattern on the Thymio\n",
    "        - mask the corner's patterns\n",
    "        - mask the goal\n",
    "        - find contours and keep the corners\n",
    "        - circle the edges on the img\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialization of the ArUco dictionary\n",
    "    aruco_dict = aruco.getPredefinedDictionary(cv2.aruco.DICT_4X4_50)\n",
    "    parameters = aruco.DetectorParameters()\n",
    "    \n",
    "    keypoints_coordinates = []\n",
    "    \n",
    "    # Image without the marker on the Thymio\n",
    "    corners, ids, rejectedImgPoints = aruco.detectMarkers(img, aruco_dict, parameters=parameters)\n",
    "    for i, marker_id in enumerate(ids):\n",
    "        #print(corners[i][0])\n",
    "        x_coordinates = corners[i][0][:, 0]\n",
    "        y_coordinates = corners[i][0][:, 1]\n",
    "        min_x, max_x = np.min(x_coordinates)-5, np.max(x_coordinates)+5\n",
    "        min_y, max_y = np.min(y_coordinates)-5, np.max(y_coordinates)+5\n",
    "        \n",
    "        # Create a white square between specified coordinates\n",
    "        mask = np.zeros_like(img, dtype=np.uint8)\n",
    "        mask[int(min_y):int(max_y), int(min_x):int(max_x)] = 255\n",
    "        img_obstacles = cv2.bitwise_or(img, mask)\n",
    "        \n",
    "    size_marker = 40\n",
    "    (h, w) = img_obstacles.shape\n",
    "    #Images without the markers on the corner and the goal\n",
    "    mask = np.zeros_like(img_obstacles, dtype=np.uint8)\n",
    "    mask[0:size_marker, 0:size_marker] = 255\n",
    "    mask[0:size_marker, w-size_marker:w] = 255\n",
    "    mask[h-size_marker:h, 0:size_marker] = 255\n",
    "    mask[h-size_marker:h, w-size_marker:w] = 255\n",
    "    x1=int(pos_goal[0]-size_marker/2)\n",
    "    x2=int(pos_goal[0]+size_marker/2)\n",
    "    y1=int(pos_goal[1]-size_marker/2)\n",
    "    y2=int(pos_goal[1]+size_marker/2)\n",
    "    mask[y1:y2, x1:x2] = 255\n",
    "    img_obstacles = cv2.bitwise_or(img_obstacles, mask)\n",
    "    \n",
    "    #reverse the image for the cv2.Canny()\n",
    "    img_obstacles = cv2.bitwise_not(img_obstacles)\n",
    "    pos_obstacle = []\n",
    "    # Apply blur to reduce noise\n",
    "    blurred = cv2.GaussianBlur(img_obstacles, (9, 9), 0)\n",
    "    # Apply edge detection\n",
    "    edges = cv2.Canny(blurred, 150, 200)\n",
    "\n",
    "    # Find contours in the image\n",
    "    contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Loop through the contours\n",
    "    for contour in contours:\n",
    "        # Approximate the contour with a polygon\n",
    "        epsilon = 0.02 * cv2.arcLength(contour, True)\n",
    "        approx = cv2.approxPolyDP(contour, epsilon, True)\n",
    "        \n",
    "        # Merge points that are too close        \n",
    "        def distance(p1, p2):\n",
    "            return np.sqrt((p1[0] - p2[0])**2 + (p1[1] - p2[1])**2)\n",
    "\n",
    "        new_approx = []\n",
    "        merged_points = set()\n",
    "\n",
    "        for i in range(len(approx)):\n",
    "            if i not in merged_points:\n",
    "                current_point = approx[i][0]\n",
    "\n",
    "                # Find points that are too close\n",
    "                close_points = [j for j in range(i + 1, len(approx)) if distance(current_point, approx[j][0]) < 10]\n",
    "\n",
    "                # Calculate the average of close points and update the list\n",
    "                if close_points:\n",
    "                    merged_points.update(close_points)\n",
    "                    close_points.append(i)\n",
    "                    average_point = np.mean(np.array([approx[j][0] for j in close_points]), axis=0)\n",
    "                    new_approx.append([average_point.astype(int)])\n",
    "                else:\n",
    "                    new_approx.append([current_point])\n",
    "        if len(new_approx)>2 and len(new_approx)<7:\n",
    "            # Convert the resulting list to a NumPy array\n",
    "            new_approx = np.array(new_approx)\n",
    "            pos = [list(point[0]) for point in new_approx]\n",
    "            #pos = [tuple(point[0]) for point in new_approx]\n",
    "            pos_obstacle.append(pos)\n",
    "            \n",
    "            for point in new_approx:\n",
    "                cv2.circle(img_obstacles, tuple(point[0]), 5, (0, 255, 0), -1)\n",
    "    #print(\"pos_obstacle :\", pos_obstacle)\n",
    "    return img_obstacles,pos_obstacle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da415e92-3120-4914-9e45-f8626a35c178",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_goal(gray_image):\n",
    "    \"\"\"\n",
    "    Find the coordinate of the goal\n",
    "    \"\"\"\n",
    "    # Setup SimpleBlobDetector parameters.\n",
    "    params = cv2.SimpleBlobDetector_Params()\n",
    "\n",
    "    # Change thresholds\n",
    "    params.minThreshold = 10\n",
    "    params.maxThreshold = 200\n",
    "\n",
    "    # Filter by Area.\n",
    "    params.filterByArea = True\n",
    "    params.minArea = 500\n",
    "    params.maxArea = 2000\n",
    "\n",
    "    # Filter by Circularity\n",
    "    params.filterByCircularity = True\n",
    "    params.minCircularity = 0.9\n",
    "\n",
    "    # Filter by Convexity\n",
    "    params.filterByConvexity = True\n",
    "    params.minConvexity = 0.9\n",
    "\n",
    "    # Filter by Inertia3\n",
    "    params.filterByInertia = True\n",
    "    params.minInertiaRatio = 0.7\n",
    "\n",
    "    # Create a blob detector with the specified parameters\n",
    "    detector = cv2.SimpleBlobDetector_create(params)\n",
    "\n",
    "    # Detect blobs.\n",
    "    keypoints = detector.detect(gray_image)\n",
    "\n",
    "    # Draw detected blobs as red circles.\n",
    "    im_with_keypoints = cv2.drawKeypoints(gray_image, keypoints, np.array([]), (255, 0, 0),\n",
    "                                          cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "    \n",
    "    pos_goal = []\n",
    "    # Retrieve the x, y coordinates of each keypoint\n",
    "    for keypoint in keypoints:\n",
    "        x, y = keypoint.pt\n",
    "        #pos_goal.append((x,y))\n",
    "        pos_goal.append(int(x))\n",
    "        pos_goal.append(int(y))\n",
    "    #print(\"position goal : \",pos_goal)\n",
    "    return pos_goal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d75bc590-1b8d-4930-b4ff-086a5cc9822e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def main():\\n    cam_port = 1 #camera 1 in my computer\\n    cam = cv2.VideoCapture(cam_port)\\n    corner_coordinates = None\\n    first_time = True\\n\\n    # Check if the camera opened successfully\\n    if not cam.isOpened():\\n        print(\"Error opening camera\")\\n        return\\n\\n    try:\\n        while True:\\n            if first_time: # wait for focus of the camera because firsts image are not good\\n                img = read_camera_image(cam)\\n                time.sleep(0.5)\\n                \\n            # Read the camera image\\n            img = read_camera_image(cam)\\n\\n            # If the image is read successfully, display it\\n            if img is not None:\\n                # Conversion to grayscale\\n                gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\\n                \\n                if first_time:\\n                    corner_coordinates = get_corner(gray) #get the position of the obstacles\\n                    if corner_coordinates is not None: #if we had get the coordinates\\n                        img_crop = crop_image(gray,corner_coordinates) #crop image\\n                        pos_goal = find_goal(img_crop)  #find goal\\n                        if pos_goal is not None:\\n                            img_obstacles,pos_obstacle = get_obstacles_coordinates(img_crop,pos_goal) #get coordinates of the obstacles\\n                            first_time = False\\n                \\n                # Display the image with the detected markers\\n                if corner_coordinates is not None:\\n                    img_crop = crop_image(gray,corner_coordinates) #crop image\\n                    raw_camera_measurement = get_position_orientation_thymio(img_crop) #get position of thymio\\n                    print(raw_camera_measurement)\\n                    \\n                    cv2.imshow(\\'Vision\\', visionning(img,gray,img_crop,img_obstacles))\\n                    \\n                else:\\n                    cv2.imshow(\\'Vision\\', img)\\n\\n            # Break the loop if the \\'Esc\\' key is pressed\\n            if cv2.waitKey(100) == 27:  # ASCII code for \\'Esc\\' key\\n                cam.release()\\n                cv2.destroyAllWindows()\\n                break   \\n            \\n            \\n\\n    finally:\\n        # Release the camera capture object and close all windows\\n        cam.release()\\n        cv2.destroyAllWindows()\\n\\n        \\nif __name__ == \"__main__\":\\n    main()'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"def main():\n",
    "    cam_port = 1 #camera 1 in my computer\n",
    "    cam = cv2.VideoCapture(cam_port)\n",
    "    corner_coordinates = None\n",
    "    first_time = True\n",
    "\n",
    "    # Check if the camera opened successfully\n",
    "    if not cam.isOpened():\n",
    "        print(\"Error opening camera\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            if first_time: # wait for focus of the camera because firsts image are not good\n",
    "                img = read_camera_image(cam)\n",
    "                time.sleep(0.5)\n",
    "                \n",
    "            # Read the camera image\n",
    "            img = read_camera_image(cam)\n",
    "\n",
    "            # If the image is read successfully, display it\n",
    "            if img is not None:\n",
    "                # Conversion to grayscale\n",
    "                gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "                \n",
    "                if first_time:\n",
    "                    corner_coordinates = get_corner(gray) #get the position of the obstacles\n",
    "                    if corner_coordinates is not None: #if we had get the coordinates\n",
    "                        img_crop = crop_image(gray,corner_coordinates) #crop image\n",
    "                        pos_goal = find_goal(img_crop)  #find goal\n",
    "                        if pos_goal is not None:\n",
    "                            img_obstacles,pos_obstacle = get_obstacles_coordinates(img_crop,pos_goal) #get coordinates of the obstacles\n",
    "                            first_time = False\n",
    "                \n",
    "                # Display the image with the detected markers\n",
    "                if corner_coordinates is not None:\n",
    "                    img_crop = crop_image(gray,corner_coordinates) #crop image\n",
    "                    raw_camera_measurement = get_position_orientation_thymio(img_crop) #get position of thymio\n",
    "                    print(raw_camera_measurement)\n",
    "                    \n",
    "                    cv2.imshow('Vision', visionning(img,gray,img_crop,img_obstacles))\n",
    "                    \n",
    "                else:\n",
    "                    cv2.imshow('Vision', img)\n",
    "\n",
    "            # Break the loop if the 'Esc' key is pressed\n",
    "            if cv2.waitKey(100) == 27:  # ASCII code for 'Esc' key\n",
    "                cam.release()\n",
    "                cv2.destroyAllWindows()\n",
    "                break   \n",
    "            \n",
    "            \n",
    "\n",
    "    finally:\n",
    "        # Release the camera capture object and close all windows\n",
    "        cam.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    main()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "898ee13e-3c71-44b7-beb8-e18961748ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init():\n",
    "    cam_port = 1 #camera 1 in my computer\n",
    "    cam = cv2.VideoCapture(cam_port)\n",
    "    first_time = True\n",
    "\n",
    "    # Check if the camera opened successfully\n",
    "    if not cam.isOpened():\n",
    "        print(\"Error opening camera\")\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            if first_time: # wait for focus of the camera because firsts image are not good\n",
    "                img = read_camera_image(cam)\n",
    "                time.sleep(0.5)\n",
    "                first_time = False\n",
    "                \n",
    "            # Read the camera image\n",
    "            img = read_camera_image(cam)\n",
    "\n",
    "            # If the image is read successfully, display it\n",
    "            if img is not None:\n",
    "                # Conversion to grayscale\n",
    "                gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "                \n",
    "                corner_coordinates = get_corner(gray) #get the position of the corners\n",
    "                if corner_coordinates is not None: #if we had get the coordinates\n",
    "                    img_crop = crop_image(gray,corner_coordinates) #crop image\n",
    "                    pos_goal = find_goal(img_crop)  #find goal\n",
    "                    if pos_goal is not None:\n",
    "                        img_obstacles,pos_obstacle = get_obstacles_coordinates(img_crop,pos_goal) #get coordinates of the obstacles\n",
    "                        pos_thymio = get_position_orientation_thymio(img_crop) #get position of thymio\n",
    "                        first_time = False\n",
    "                        print(\"pos_goal : \", pos_goal)\n",
    "                        print(\"pos_obstacle : \",pos_obstacle)\n",
    "                        print(\"pos_thymio : \",pos_thymio)\n",
    "                        width=60\n",
    "                        goal_pos = [[pos_goal[0]-20, pos_goal[1]-20], [pos_goal[0]-20, pos_goal[1]+20], [pos_goal[0]+20, pos_goal[1]+20], [pos_goal[0]+20, pos_goal[1]-20]]\n",
    "                        start_pos = [[pos_thymio[0]-50, pos_thymio[1]-50], [pos_thymio[0]-50, pos_thymio[1]+50], [pos_thymio[0]+50, pos_thymio[1]+50], [pos_thymio[0]+50, pos_thymio[1]-50]]\n",
    "                        \n",
    "                        #width = 0.2\n",
    "                        #obs_list = [[[300, 200], [400, 200], [400, 300], [300, 300]], [[100, 200], [200, 400], [100, 400]]]\n",
    "                        #start_pos = [[100, 100], [150, 100], [150, 150], [100, 150]]\n",
    "                        robot_dir0 = 0\n",
    "                        #goal_pos = [[450, 450], [500, 450], [500, 500], [450, 500]]\n",
    "                        findPath(pos_obstacle, start_pos, robot_dir0, goal_pos, width)\n",
    "                        #findPath(pos_obstacle, start_pos, pos_thymio[2], pos_goal, width)\n",
    "                        return None\n",
    "                \n",
    "    finally:\n",
    "        # Release the camera capture object and close all windows\n",
    "        cam.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96737959-d928-4325-b9af-d4a3b3018933",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos_goal :  [511, 153]\n",
      "pos_obstacle :  [[[97, 374], [40, 431], [135, 495], [162, 464]], [[282, 360], [282, 481], [346, 481], [346, 450], [314, 447], [313, 361]], [[480, 313], [438, 317], [448, 482], [494, 478]], [[99, 183], [84, 189], [67, 185]], [[89, 163], [94, 171], [91, 181]], [[52, 159], [54, 178], [81, 153], [96, 163], [103, 179], [65, 151]], [[38, 63], [40, 100], [79, 98], [76, 61], [52, 60]], [[364, 39], [283, 48], [287, 115], [329, 152], [370, 111]]]\n",
      "pos_thymio :  [59, 80, -1.91]\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    init()\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc40627-1853-4814-8397-870de623fae7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ada] *",
   "language": "python",
   "name": "conda-env-ada-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
